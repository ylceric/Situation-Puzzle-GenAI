import streamlit as st
import streamlit_chatbox as stc
import time
import api_request
import streamlit_scrollable_textbox as stx
import pandas as pd
import random
import os
import glob

st.set_page_config(
    page_title='Situation Puzzle', 
    page_icon='üß©'
)

chat_box = stc.ChatBox()

# config sidebar
if st.sidebar.button('üîÑ New Game'): 
    if os.path.isfile('question.tmp'): 
        os.remove('question.tmp')
    chat_box.reset_history()
    st.rerun()

bot_llm = st.sidebar.radio('Bot LLM: ', ['OpenAI-GPT-4.0', 'OpenAI-GPT-3.5', 'Gemini Pro'])
image_gen_model = st.sidebar.radio('Image GenAI: ', ['DALL¬∑E 3'])
image_style = st.sidebar.radio('Image Style: ', ['Comic', 'Realistic'])
p_avatar = st.sidebar.selectbox('Choose Avatar: ', glob.glob('avatars/*.jpg'))
st.sidebar.image(p_avatar)
st.sidebar.divider()
show_quick_question = st.sidebar.button('Question Suggestion')
st.sidebar.divider()

st.sidebar.markdown('**This demo presented by:**')
st.sidebar.markdown('*University of Washington - Foster School of Business*')
st.sidebar.markdown('*:violet[Class of 2024 - MSIS Purple Team 9]*')

st.header('AIü§ñ vs. Human Playerüß© - AI Questions (BETA)', divider='rainbow')
st.text('Hit New Game Button on the sidebar if you want generate new AI puzzles')

is_start = True
# set up question and answer of situation puzzle
if os.path.isfile('question.tmp'): 
    temp_file = pd.read_csv('question.tmp')
    QUESTION = temp_file['question'][0]
    ANSWER = temp_file['answer'][0]
    
else: 
    st.subheader('Please choose a start topic to generate...')
    st.markdown("**Disclaimer:** The Puzzles in this page is fully generated by AI, not supervised by human. It can make errors and contents can be too easy or offensive.")
    topic = st.selectbox('Topics: ', ['Movies', 'Games', 'Minecraft', 'Harry Porter', 'Seattle', 'Custom'])
    if topic == 'Custom': 
        topic = st.text_input("Type the topic of your choice...")

    is_start = False
    if st.button('Start'): 
        is_start = True
        INIT_TOPIC_PROMPT = f"I want you to pretend to be a professional Situation Puzzle writer. Users want to have some fresh puzzles that related to their own topics. I will give you the topic at the next prompt. For the puzzle created, it can be scary or funny. It needs to be interesting. But, please make sure the puzzle questions and answers are not offensive to a real person. Here is an example of a good situation puzzle: \nQuestion: A boy walked into a restaurant, drank a bowl of turtle soup, and then committed suicide.\nAnswer: The boy went to sea with his father and encountered a storm on the way. When he was dying, his father used his own meat to make him a bowl of soup and lied to his son that it was soup made from sea turtles. The father sacrificed himself to save the child. life. After the child landed safely, he went to the restaurant and ordered a bowl of real turtle soup. He found that it didn't taste like that. He immediately understood and committed suicide.\nNow begin to generate an interesting situation puzzle."

        with st.spinner('AI is Now Generating A Puzzle for You...'):
            topic_llm = api_request.GPT(INIT_TOPIC_PROMPT)
            q_and_a = topic_llm.generate_puzzle(topic)

        QUESTION = q_and_a[0]
        ANSWER = q_and_a[1]

        pd.DataFrame({'question': [QUESTION], 'answer': [ANSWER]}).to_csv('question.tmp')


if is_start:
    INIT_PROMPT = f"I want you to pretend to be a professional game host of Situation Puzzle. The game rule is as follows: You are hosting the puzzle and the user asking questions which can only be answered with a 'yes' or 'no' answer. Depending upon the settings and level of difficulty, other answers, hints or simple explanations of why the answer is yes or no, may be considered acceptable. The puzzle is solved when one of the players is able to recite most of the narrative the host had in mind, in particular explaining whatever aspect of the initial scenario was puzzling. When the player recite most of situation correctly, you tell the user what exact happen. If the user are heading to a topic completely unrelated to this situation puzzle, please stop the user. Now, here is the puzzle: {QUESTION}, the answer to this puzzle is {ANSWER} Now, user is going to ask you question. The followings are the player question: \n"

    # header
    stx.scrollableTextbox(QUESTION, height=150)

    llm_avatar = "assistant"

    # initialize llm
    if bot_llm == 'OpenAI-GPT-4.0': 
        llm = api_request.GPT(INIT_PROMPT)
        llm_avatar = 'avatars/LLM/OpenAI-GPT.jpg'
    elif bot_llm == 'OpenAI-GPT-3.5': 
        llm = api_request.GPT(INIT_PROMPT, is_4=False)
        llm_avatar = 'avatars/LLM/OpenAI-GPT.jpg'
    elif bot_llm == 'Gemini Pro':
        llm = api_request.GeminiText(INIT_PROMPT)
        llm_avatar = 'avatars/LLM/Gemini.jpg'


    chat_box = stc.ChatBox(user_avatar=p_avatar, assistant_avatar=llm_avatar)
    chat_box.output_messages()

    guess_mode = st.toggle('Ready to Guess')

    if show_quick_question:  
        with st.spinner('Wait for Quick Questions...'): 
            questions = llm.generate_questions(chat_box.history, QUESTION)

        st.write('Here are Question Suggestions for you...')
        stx.scrollableTextbox('\n'.join(questions))


    if user_query := st.chat_input('Input your question here. If you are ready to guess, press on guess on the sidebar, then input'):
        chat_box.user_say(user_query)

        if guess_mode: 
            st.text('Player starts to guess...')
            if llm.check_answer(chat_box.history): 
                st.subheader('', divider='rainbow')
                st.success('You are Correct!', icon="‚úÖ")
                st.subheader('Here is the correct answer...')
                stx.scrollableTextbox(ANSWER, height=150)
                st.subheader('Here is the feedback generated to you...')
                with st.spinner('AI Generating...'):
                    stx.scrollableTextbox(llm.feedback(chat_box.history), height=300)

                os.remove('question.tmp')

                # generate image
                with st.spinner('Wait for Image...'):
                    if image_gen_model == 'DALL¬∑E 3': 
                        image_gen = api_request.Dalle(style=image_style)
                    image_url = image_gen.gen_image(ANSWER)
                    st.image(image_url)

            else:
                st.error('Sorry, You are wrong. Please continue...', icon="‚ùå")

        else: 
            generator = llm.answer(chat_box.history)
            elements = chat_box.ai_say(
                [
                    stc.Markdown("thinking", in_expander=False,
                                expanded=False, title="answer"),
                    stc.Markdown("", in_expander=False, title="references"),
                ]
            )
            time.sleep(0.3)
            text = ""
            for chunk in generator:
                if 'OpenAI' in bot_llm:
                    buffer = chunk.choices[0].delta.content
                else:
                    buffer = chunk.text
                if buffer is not None: 
                    text += buffer
                chat_box.update_msg(text, element_index=0, streaming=True)
            chat_box.update_msg(text, element_index=0, streaming=False, state="complete")
